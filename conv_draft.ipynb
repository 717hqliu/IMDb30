{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Conv1d 测试\n",
    "- 一维卷积用于于文本数据，只在宽度上卷积，高度上不卷积\n",
    "- 参数说明：\n",
    "    - in_channels: 词向量维度\n",
    "    - out_channels: 卷积产生的通道数，也就是卷积核的数量（一个卷积核产生一个输出通道）\n",
    "    - kernel_size: 卷积核的尺寸；卷积核的第二个尺寸由 in_channels 决定，所以卷积核的实际大小为 kernel_size * in_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d = nn.Conv1d(in_channels=256, out_channels=100, kernel_size=2)\n",
    "input = torch.randn(32, 35, 256)    # batch size 大小为32，句子最大长度为35，词向量维度为256\n",
    "print(input.shape)\n",
    "input = input.permute(0,2,1)\n",
    "print(input.shape)\n",
    "output = conv1d(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1d = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=1)\n",
    "input = torch.randn(32, 3, 50)\n",
    "print(input.shape)\n",
    "output = conv1d(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Conv2d 测试\n",
    "- 2 维卷积用于图像卷积，对宽度和高度都卷积\n",
    "- 参数说明：\n",
    "    - in_channels 表示输入图片的通道数，黑白图片就是 1 通道，RGB 图片是 3 通道\n",
    "    - out_channels 输出通道数量，等于卷积核数量\n",
    "    - kernel_size 的实际大小是 5×5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(nn.Conv2d)\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=5, kernel_size=(2,3))   # 需要 5 个 2*3 的卷积核\n",
    "# 输入需要是 4 维的，格式为 (batch, channel, Height, Width)\n",
    "input = torch.randn(2, 1, 10, 3)    # batch size 大小为2，图片通道数为1，图片大小为10*3（模拟三元组矩阵）\n",
    "print(input.shape)\n",
    "output = conv2d(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Conv3d 测试\n",
    "- 3 维卷积可以用于视频卷积，可以同时处理多帧（张）图片\n",
    "- 参数说明：\n",
    "    - in_channels 输入中每帧图片的通道数\n",
    "    - out_channels 输出中每帧图片的通道数\n",
    "    - kernel_size 过滤器尺寸，大小为三维 (a,b,c)，表示每次处理 a 帧图片，每帧图片的大小是(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 5, 55, 34])\n"
     ]
    }
   ],
   "source": [
    "# in_channels 图片通道数是3，out_channels 需要四个卷积核，kernel size 每次处理 3 帧图片，卷积核大小为 7x7\n",
    "conv3d = nn.Conv3d(in_channels=3, out_channels=4, kernel_size=(3,6,7))\n",
    "# 输入需要是 5 维的，格式为 (batch, channel, Depth, Height, Width)\n",
    "input = torch.randn(1, 3, 7, 60, 40)    # batch size 为 1，每张图片的通道数为 3，一段视频包含 7 帧图片，图片大小为 60x40\n",
    "output = conv3d(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv3D 草稿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 16, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 假设 dim = 30，dim = 5，dim = 6\n",
    "# 输入图片的通道数是 1，输出通道/需要的卷积核数量是 16，kernel 每次处理两帧图片，卷积核大小为 3*4\n",
    "conv3d = nn.Conv3d(in_channels=1, out_channels=16, kernel_size=(2,3,4))\n",
    "# 输入是 5 维的，batch size 为 5，每帧图片通道数为 1，一段视频包含 3 帧图片（h,r,t），每帧图片大小为 5*6\n",
    "input = torch.randn(5, 1, 3, 5, 6)\n",
    "output = conv3d(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.BatchNorm1d 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(nn.BatchNorm1d)\n",
    "bn = nn.BatchNorm1d(num_features = 5)\n",
    "input = torch.randn(32, 5, 25)    # batch size * sentence words * embedding size\n",
    "# print(input)\n",
    "output = bn(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.BatchNorm2d 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = nn.BatchNorm2d(num_features=5)\n",
    "input = torch.randn(2,5,3,1)\n",
    "# print(input)\n",
    "output = bn(input )\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.Dropout 测试\n",
    "- 随机将输入张量中的部分元素设置为 0\n",
    "- 参数说明:\n",
    "    - p 将元素设置为 0 的概率，默认为 0.5\n",
    "    - inplace 若设置为 True，会在原地执行操作，默认为 False\n",
    "- 输入可以为任意形状，输出和输入的形状相同\n",
    "- 还有一个 dropout 函数：nn.functional.dropout，其中 training 值默认为 False，没有启用 dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = nn.Dropout(p=0.1)\n",
    "input = torch.randn(5, 3)\n",
    "output = dropout(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 常见（非线性）激活函数测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = nn.ReLU()\n",
    "softplus = nn.Softplus()    # softplus 就是 relu 的平滑版本\n",
    "tanh = nn.Tanh()\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "input = torch.randn(2,5,3,1)\n",
    "print(input)\n",
    "output = softplus(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 线性层 nn.Linear 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(in_features=30, out_features=5, bias=False)    # 参数 bias 默认为 True，若设置为 False，则不会学习附加偏差\n",
    "input = torch.randn(2, 30)\n",
    "print(input.shape)\n",
    "# input = input.view(1, -1)\n",
    "# print(input)\n",
    "output = fc(input)\n",
    "print(output.shape)\n",
    "output = output.view(-1)\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn.init.xavier_uniform_ 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(in_features=5, out_features=3)\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=2)\n",
    "print(fc.weight.data)\n",
    "# print(conv2d.weight.data)\n",
    "nn.init.xavier_uniform_(fc.weight.data)\n",
    "print(fc.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1,5,6,1)\n",
    "print(a)\n",
    "a = a.view(-1, 5*6)\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.randn(10,1)\n",
    "print(b)\n",
    "b = b.view(-1)\n",
    "print(b.shape)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = torch.randn(5)\n",
    "batch_y = torch.Tensor([1,1,-1,0,-1])\n",
    "softplus = nn.Softplus()\n",
    "output = batch_y * score\n",
    "print(output)\n",
    "output = softplus(output)\n",
    "print(output)\n",
    "a = torch.randn(5,3)\n",
    "print(a)\n",
    "mean = torch.mean(a, dim=0, keepdim = True)\n",
    "print(mean)\n",
    "print(torch.mean(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn(5)\n",
    "print(t)\n",
    "print(t.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x =  np.empty([3,2],dtype=int)\n",
    "print(x)\n",
    "x = torch.from_numpy(x)\n",
    "print(x)\n",
    "# x = x.to(torch.device(\"cuda\"))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.Tensor([ 0.5697, -0.4930,  0.3155, -0.2275, -1.7942])\n",
    "print(h)\n",
    "print(h ** 2)\n",
    "print(torch.mean(h ** 2))\n",
    "print(h.norm(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3)\n",
    "print(conv_layer.parameters())\n",
    "for w in conv_layer.parameters():\n",
    "    print(w.norm(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base(py3.7)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
