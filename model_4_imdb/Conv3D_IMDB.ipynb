{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注意：调用 Base.so 只能在 Linux 上运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import ctypes\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31343\n",
      "30\n",
      "92680\n",
      "11585\n",
      "11586\n",
      "926\n"
     ]
    }
   ],
   "source": [
    "# 使用 GPU 的设置\n",
    "use_gpu = True if torch.cuda.is_available() else False\n",
    "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
    "\n",
    "class Config():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.dim = 50\n",
    "        self.dim1 = 5\n",
    "        self.dim2 = self.dim // self.dim1\n",
    "        \n",
    "        # config of training\n",
    "        self.learning_rate = 0.01\n",
    "        self.batch_num = 100\n",
    "        self.epoch_num = 1000\n",
    "        self.lmbda = 0.2\n",
    "        self.opt_method = \"Adagrad\"\n",
    "        \n",
    "        # config of model storage\n",
    "        self.vali_epoch = 100\n",
    "        self.save_epoch = 100\n",
    "        self.mode = \"train\"        # \"train\" or \"test\"\n",
    "        self.checkpoint_path = \"./checkpoints_Conv3d\"\n",
    "        \n",
    "        # 调用 C++ 封装的库文件 Base.io\n",
    "        self.clib = ctypes.cdll.LoadLibrary(\"./Base.so\")\n",
    "        self.dataset = \"IMDB_sub\"    # \"WN18\" or \"WN18RR\" or \"FB15K\" or \"FB15K237\"\n",
    "        self.in_path = \"./\" + self.dataset + \"/\"    # 将数据集路径传递给 Base.io\n",
    "\n",
    "        # negative sampling\n",
    "        self.clib.sampling.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_int64,\n",
    "            ctypes.c_int64,\n",
    "            ctypes.c_int64,\n",
    "        ]\n",
    "        \n",
    "        # validation dataset\n",
    "        self.clib.getValidHeadBatch.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "        ]\n",
    "        self.clib.getValidTailBatch.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "        ]\n",
    "        self.clib.validHead.argtypes = [ctypes.c_void_p]\n",
    "        self.clib.validTail.argtypes = [ctypes.c_void_p]\n",
    "        \n",
    "        # link prediction test dataset\n",
    "        self.clib.getHeadBatch.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "        ]\n",
    "        self.clib.getTailBatch.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "        ]\n",
    "        self.clib.testHead.argtypes = [ctypes.c_void_p]\n",
    "        self.clib.testTail.argtypes = [ctypes.c_void_p]\n",
    "        \n",
    "        self.test_file = \"\"\n",
    "        \n",
    "        self.clib.setInPath(ctypes.create_string_buffer(self.in_path.encode(), len(self.in_path)*2))\n",
    "        self.clib.setTestFilePath(ctypes.create_string_buffer(self.test_file.encode(), len(self.test_file)*2))\n",
    "        \n",
    "        self.clib.setBern(0)\n",
    "        self.clib.setWorkThreads(8)\n",
    "        self.clib.randReset()\n",
    "        \n",
    "        self.clib.importTrainFiles()   # 还是会崩掉，试试加上所有文件试试\n",
    "        self.clib.importTestFiles()\n",
    "        # self.clib.importTypeFiles()    # model test 需要用到这个\n",
    "        \n",
    "        # 问题出在这里，import 文件时服务会崩掉\n",
    "        # 原因有二：1. 三元组文件不是用 tab 而是空格来分隔的；2. 需要 \"type_constrain.txt\" 文件\n",
    "        \n",
    "        # 数据集统计信息\n",
    "        self.ent_num = self.clib.getEntityTotal()\n",
    "        self.rel_num = self.clib.getRelationTotal()\n",
    "        self.train_num = self.clib.getTrainTotal()\n",
    "        self.vali_num = self.clib.getValidTotal()\n",
    "        self.test_num = self.clib.getTestTotal()\n",
    "        \n",
    "        self.batch_size = int(self.train_num / self.batch_num)\n",
    "\n",
    "con = Config()\n",
    "# print(con.clib)\n",
    "# print(con.in_path)\n",
    "print(con.ent_num)\n",
    "print(con.rel_num)\n",
    "print(con.train_num)\n",
    "print(con.vali_num)\n",
    "print(con.test_num)\n",
    "print(con.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(30, 50)\n"
     ]
    }
   ],
   "source": [
    "# 为 CPU 设置用于生成随机数的种子，以使得结果是确定的\n",
    "torch.manual_seed(123)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(123)    # 使用多个 GPU 的话，为所有的 GPU 设置种子，torch.cuda.manual_seed() 是为当前 GPU 设置种子\n",
    "    \n",
    "class Conv3D(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(Conv3D, self).__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        self.batch_h = None\n",
    "        self.batch_t = None\n",
    "        self.batch_r = None\n",
    "        self.batch_y = None\n",
    "        \n",
    "        self.ent_embeddings = nn.Embedding(self.config.ent_num, self.config.dim)\n",
    "        self.rel_embeddings = nn.Embedding(self.config.rel_num, self.config.dim)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm3d(num_features=1)\n",
    "        self.bn2 = nn.BatchNorm3d(num_features=64)\n",
    "        self.conv_layer = nn.Conv3d(in_channels=1, out_channels=64, kernel_size=(3,2,4))\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.nonlinear = nn.ReLU()\n",
    "        self.conv_size = 64*(3-3+1)*(self.config.dim1-2+1)*(self.config.dim2-4+1)\n",
    "        self.fc_layer = nn.Linear(in_features=self.conv_size, out_features=1)\n",
    "        \n",
    "        self.criterion = nn.Softplus()\n",
    "        \n",
    "        # 初始化 embeddings 以及卷积层、全连接层的参数\n",
    "        nn.init.xavier_uniform_(self.ent_embeddings.weight.data)\n",
    "        nn.init.xavier_uniform_(self.rel_embeddings.weight.data)\n",
    "        nn.init.xavier_uniform_(self.conv_layer.weight.data)\n",
    "        nn.init.xavier_uniform_(self.fc_layer.weight.data)\n",
    "        \n",
    "        \n",
    "    def cal_score(self):\n",
    "        h = self.ent_embeddings(self.batch_h)\n",
    "        r = self.rel_embeddings(self.batch_r)\n",
    "        t = self.ent_embeddings(self.batch_t)\n",
    "        \n",
    "        h = h.view(-1, 1, self.config.dim1, self.config.dim2)\n",
    "        r = r.view(-1, 1, self.config.dim1, self.config.dim2)\n",
    "        t = t.view(-1, 1, self.config.dim1, self.config.dim2)\n",
    "        cube = torch.cat([h,r,t], 1)\n",
    "        \n",
    "        x = cube.unsqueeze(1)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv_layer(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.nonlinear(x)\n",
    "        x = x.view(-1, self.conv_size)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_layer(x)\n",
    "        \n",
    "        score = x.view(-1)\n",
    "        return -score\n",
    "        \n",
    "    def forward(self):\n",
    "        batch_score = self.cal_score()\n",
    "        \n",
    "        h = self.ent_embeddings(self.batch_h)\n",
    "        r = self.rel_embeddings(self.batch_r)\n",
    "        t = self.ent_embeddings(self.batch_t)\n",
    "        \n",
    "        # l2_regular = h.norm(2) + r.norm(2) + t.norm(2)\n",
    "        l2_regular = torch.mean(h ** 2) + torch.mean(r ** 2) + torch.mean(t ** 2)\n",
    "        \n",
    "        for p in self.conv_layer.parameters():\n",
    "            l2_regular += p.norm(2)\n",
    "        for p in self.fc_layer.parameters():\n",
    "            l2_regular += p.norm(2)\n",
    "        \n",
    "        mean = torch.mean(self.criterion(self.batch_y * batch_score))\n",
    "        regular = self.config.lmbda * l2_regular\n",
    "        # print(mean, regular)\n",
    "        return mean + regular\n",
    "    \n",
    "conv3d = Conv3D(con)\n",
    "conv3d.batch_h = torch.LongTensor([1,40,5,4,6,79])\n",
    "conv3d.batch_r = torch.LongTensor([5,4,2,4,1,9])\n",
    "conv3d.batch_t = torch.LongTensor([3,60,80,3,56,7])\n",
    "conv3d.batch_y = torch.LongTensor([1,1,1,-1,-1,-1])\n",
    "conv3d()\n",
    "print(conv3d.rel_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    \n",
    "    def __init__(self, config, model):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.clib = self.config.clib\n",
    "        \n",
    "    def set_model(self, mode = 'train'):\n",
    "        self.model.to(device)\n",
    "        \n",
    "        if mode == 'train':    # 训练模型\n",
    "            print(\"Initializing training model...\")\n",
    "            # 为训练模型设定优化器\n",
    "            if self.config.opt_method == \"Adagrad\":\n",
    "                self.optimizer = optim.Adagrad(\n",
    "                    params = self.model.parameters(),\n",
    "                    lr = self.config.learning_rate,\n",
    "                    lr_decay = 0,\n",
    "                    weight_decay = 0\n",
    "                )\n",
    "            elif self.config.opt_method == \"Adadelta\":\n",
    "                self.optimizer = optim.Adadelta(\n",
    "                    params = self.model.parameters(),\n",
    "                    lr = self.config.learning_rate,\n",
    "                    weight_decay = 0\n",
    "                )\n",
    "            elif self.config.opt_method == \"Adam\":\n",
    "                self.optimizer = optim.Adam(\n",
    "                    params = self.model.parameters(),\n",
    "                    lr = self.config.learning_rate,\n",
    "                    weight_decay = 0\n",
    "                )\n",
    "            else:    # 不是以上三种的话就用 SGD\n",
    "                self.optimizer = optim.SGD(\n",
    "                    params = self.model.parameters(),\n",
    "                    lr = self.config.learning_rate,\n",
    "                    weight_decay = 0\n",
    "                )\n",
    "            print(\"Training model has been initialized.\")\n",
    "        else:                           # mode == 'test'，从 checkpoints 中载入模型，用于测试\n",
    "            print(\"Fetching model for test...\")\n",
    "            ckpt_path = os.path.join(\"./checkpoints_Conv3d/\", self.config.dataset + \"-netparam_best\" + \".ckpt\")  \n",
    "            self.model.load_state_dict(torch.load(ckpt_path))\n",
    "            self.model.to(device)\n",
    "            self.model.eval()\n",
    "            print(\"Test model has been loaded.\")\n",
    "    \n",
    "    def get_parameters(self, param_dict, mode = 'numpy'):\n",
    "        '''\n",
    "        从 model 中剥离出参数\n",
    "        '''\n",
    "        res = dict()\n",
    "        for param in param_dict:\n",
    "            if mode == 'numpy':\n",
    "                res[param] = param_dict[param].cpu().numpy()\n",
    "            elif mode == 'list':\n",
    "                res[param] = param_dict[param].cpu().numpy().tolist()\n",
    "            else:\n",
    "                res[param] = param_dict[param]\n",
    "        return res\n",
    "    \n",
    "    def neg_sample(self):\n",
    "        '''\n",
    "        对 batch 数据进行负采样\n",
    "        无返回值\n",
    "        '''\n",
    "        self.negative_ent = 1    # 负样本实体一个\n",
    "        self.negative_rel = 0\n",
    "        self.batch_seq_size = self.config.batch_size * (1 + self.negative_ent + self.negative_rel)\n",
    "        \n",
    "        self.batch_h = np.zeros(self.batch_seq_size, dtype = np.int64)    # 容量是 batch size 的两倍，用于盛放负样本\n",
    "        self.batch_t = np.zeros(self.batch_seq_size, dtype = np.int64)\n",
    "        self.batch_r = np.zeros(self.batch_seq_size, dtype = np.int64)\n",
    "        self.batch_y = np.zeros(self.batch_seq_size, dtype = np.float32)\n",
    "\n",
    "        self.batch_h_addr = self.batch_h.__array_interface__[\"data\"][0]\n",
    "        self.batch_t_addr = self.batch_t.__array_interface__[\"data\"][0]\n",
    "        self.batch_r_addr = self.batch_r.__array_interface__[\"data\"][0]\n",
    "        self.batch_y_addr = self.batch_y.__array_interface__[\"data\"][0]\n",
    "        \n",
    "        # 这一步将数据集中实体和关系的 id 传进来\n",
    "        # print(self.batch_y)\n",
    "        self.clib.sampling(\n",
    "            self.batch_h_addr,    # 头实体 batch 的地址，传给 clib 函数的指针\n",
    "            self.batch_t_addr,\n",
    "            self.batch_r_addr,\n",
    "            self.batch_y_addr,\n",
    "            self.config.batch_size,\n",
    "            self.negative_ent,\n",
    "            self.negative_rel\n",
    "        )\n",
    "    \n",
    "    def train_batch(self):\n",
    "        '''\n",
    "        使用 self.model 训练一个 batch 的数据\n",
    "        return: 该 batch 的 loss\n",
    "        '''\n",
    "        self.model.train()\n",
    "        # 向模型喂一个 batch 的数据\n",
    "        self.model.batch_h = torch.from_numpy(self.batch_h).to(device)    # numpy 数组转为 Tensor\n",
    "        self.model.batch_t = torch.from_numpy(self.batch_t).to(device)\n",
    "        self.model.batch_r = torch.from_numpy(self.batch_r).to(device)\n",
    "        self.model.batch_y = torch.from_numpy(self.batch_y).to(device)\n",
    "        # print(self.model.batch_y)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.model()    # 会自动调用 forward() 函数\n",
    "        loss.backward()        # 误差反向传播\n",
    "        # 由于在反向传播的过程中会发生梯度消失/爆炸，因此设定阈值，当梯度大于/小于阈值时候，将梯度缩放为阈值\n",
    "        nn.utils.clip_grad_norm_(parameters = self.model.parameters(), max_norm = 0.5, norm_type = 2)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def test_batch(self, model, batch_h, batch_t, batch_r):\n",
    "        '''\n",
    "        测试一个 batch 的数据\n",
    "        batch_h: numpy array\n",
    "        batch_t: numpy array\n",
    "        batch_r: numpy array\n",
    "        return: 该 test batch 的三元组得分\n",
    "        '''\n",
    "        # model.train()  将模块设置为训练模式，使用BatchNormalizetion()和Dropout()\n",
    "        # model.eval()   将模块设置为评估模式，不使用BatchNormalization()和Dropout()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            model.batch_h = torch.from_numpy(batch_h).to(device)\n",
    "            model.batch_t = torch.from_numpy(batch_t).to(device)\n",
    "            model.batch_r = torch.from_numpy(batch_r).to(device)\n",
    "        # print(\"test batch res is:\")\n",
    "        res = model.cal_score().cpu().data.numpy()\n",
    "        # print(res.shape)\n",
    "        return res\n",
    "        \n",
    "    def validation(self, model):\n",
    "        '''\n",
    "        验证模型\n",
    "        '''\n",
    "        model.eval()\n",
    "        self.vali_h = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.vali_t = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.vali_r = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.vali_h_addr = self.vali_h.__array_interface__[\"data\"][0]    # array 的内存地址\n",
    "        self.vali_t_addr = self.vali_t.__array_interface__[\"data\"][0]\n",
    "        self.vali_r_addr = self.vali_r.__array_interface__[\"data\"][0]\n",
    "        \n",
    "        self.clib.validInit()\n",
    "        self.clib.getValidHit10.restype = ctypes.c_float\n",
    "        \n",
    "        print(\"The total number of validation triplets is %d\" % self.config.vali_num)\n",
    "        for i in range(self.config.vali_num):\n",
    "            sys.stdout.write(\"%d \\r\" % i)    # 动态打印输出\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            # 之前运行这一步服务就会\n",
    "            # 原因：self.vali_r = np.zeros(self.config.ent_num, dtype=np.int64)，写成了rel_num，以为是原代码错了，但其实没有，自作聪明的结果\n",
    "            self.clib.getValidHeadBatch(self.vali_h_addr, self.vali_t_addr, self.vali_r_addr)\n",
    "            res = self.test_batch(model, self.vali_h, self.vali_t, self.vali_r)\n",
    "            self.clib.validHead(res.__array_interface__[\"data\"][0])\n",
    "            \n",
    "            self.clib.getValidTailBatch(self.vali_h_addr, self.vali_t_addr, self.vali_r_addr)\n",
    "            res = self.test_batch(model, self.vali_h, self.vali_t, self.vali_r)\n",
    "            self.clib.validTail(res.__array_interface__[\"data\"][0])\n",
    "            \n",
    "            # 第一个 batch 的 Hits@10 res 是 0.0\n",
    "        return self.clib.getValidHit10()   # 训练时的验证步骤，需要返回 hits@10 结果\n",
    "    \n",
    "    def test(self, model):\n",
    "        self.set_model(mode = 'test')\n",
    "        # 只做链接预测实验\n",
    "        \n",
    "        print(\"The total number of test triplets is %d\" % self.config.test_num)\n",
    "\n",
    "        self.test_h = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.test_t = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.test_r = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.test_h_addr = self.test_h.__array_interface__[\"data\"][0]\n",
    "        self.test_t_addr = self.test_t.__array_interface__[\"data\"][0]\n",
    "        self.test_r_addr = self.test_r.__array_interface__[\"data\"][0]\n",
    "        \n",
    "        print(\"Testing...\")\n",
    "        for i in range(self.config.test_num):\n",
    "            sys.stdout.write(\"%d \\r\" % i)    # 动态打印输出\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            self.clib.getHeadBatch(self.test_h_addr, self.test_t_addr, self.test_r_addr)\n",
    "            res = self.test_batch(model, self.test_h, self.test_t, self.test_r)\n",
    "            self.clib.testHead(res.__array_interface__[\"data\"][0])\n",
    "\n",
    "            self.clib.getTailBatch(self.test_h_addr, self.test_t_addr, self.test_r_addr)\n",
    "            res = self.test_batch(model, self.test_h, self.test_t, self.test_r)\n",
    "            self.clib.testTail(res.__array_interface__[\"data\"][0])\n",
    "            \n",
    "            # 最终输出在 shell 上的结果中，left 代表头实体，right 代表尾实体\n",
    "            # testHead() 和 testTail() 两个函数需要 type_constrain.txt 文件\n",
    "            # testHead() 中的 head_type 和 testTail() 中的 tail_type 两个变量是由 importTypeFiles() 函数运行得到的\n",
    "\n",
    "        self.clib.test_link_prediction()\n",
    "        print(\"Finished testing.\")\n",
    "    \n",
    "    def train_model(self):\n",
    "        if not os.path.exists(self.config.checkpoint_path):\n",
    "            os.mkdir(self.config.checkpoint_path)\n",
    "            \n",
    "        self.set_model(mode = self.config.mode)\n",
    "        \n",
    "        best_epoch = 0\n",
    "        best_hits10 = 0.0\n",
    "        best_model = self.model\n",
    "\n",
    "        epochs = tqdm(range(self.config.epoch_num))\n",
    "        \n",
    "        for epoch in epochs:\n",
    "            res = 0.0    # 用于累加本 epoch 各个 batch 的 loss\n",
    "            for batch in range(self.config.batch_num):    # 训练一个batch\n",
    "                self.neg_sample()    # 负采样\n",
    "                loss = self.train_batch()    # 训练一个 batch 为一个 step\n",
    "                # print(\"batch loss: %f\" % loss)\n",
    "                res += loss\n",
    "                \n",
    "            epochs.set_description(\"Epoch %d | loss: %f\" % (epoch, res))    # 输出进度条的描述\n",
    "            # 问题：loss到了69左右就不下降了，但是 50 epoch 后验证集正确率还是达到了 50多（但不再增长），所以应该问题不大\n",
    "            # 应该是网络比较复杂，在数据集上很快就拟合好了\n",
    "            # 验证集准确率上升很快，测试集上却没有跑出结果，应该是过拟合了\n",
    "            # 下一步是学习 ConvE 疯狂 dropout\n",
    "            \n",
    "            if epoch == 0:\n",
    "                embed_save_path = os.path.join(self.config.checkpoint_path, \"embeddings\", self.config.dataset + \"-embed-\" + str(0) + \".json\")\n",
    "                with open(embed_save_path, 'w') as f:\n",
    "                    f.write(json.dumps(self.get_parameters(self.model.state_dict(), 'list')))\n",
    "                print(\"Finished Storing the model and embeddings of epoch 0.\")\n",
    "            \n",
    "            if (epoch + 1) % self.config.save_epoch == 0:\n",
    "                epochs.set_description(\"Epoch %d has finished, loss is %f, saving checkpoint ...\" % (epoch, res))\n",
    "                # 存储 checkpoint\n",
    "                save_path = os.path.join(self.config.checkpoint_path, self.config.dataset + \"-\" + str(epoch) + \".ckpt\")\n",
    "                torch.save(self.model.state_dict(), save_path)\n",
    "            \n",
    "            if (epoch + 1) % self.config.vali_epoch == 0:\n",
    "                epochs.set_description(\"Epoch %d has finished, loss is %f, validating ...\" % (epoch, res))\n",
    "                hits10 = self.validation(self.model)\n",
    "                print(\"hits@10 of this validation epoch is: %.8f\" % hits10)\n",
    "#                 print(\"Testing on test set ...\")\n",
    "#                 self.test(self.model)\n",
    "#                 print(\"Test result is printed on Linux shell.\")\n",
    "                \n",
    "                if hits10 > best_hits10:\n",
    "                    best_hits10 = hits10\n",
    "                    best_epoch = epoch\n",
    "                    best_model = self.model\n",
    "                    \n",
    "                # 每到 vali_epoch 要把训练的 embedding 存下来，以便做可视化\n",
    "                embed_save_path = os.path.join(self.config.checkpoint_path, \"embeddings\", self.config.dataset + \"-embed-\" + str(epoch) + \".json\")\n",
    "                with open(embed_save_path, 'w') as f:\n",
    "                    f.write(json.dumps(self.get_parameters(self.model.state_dict(), 'list')))\n",
    "                print(\"Finished Storing the model and embeddings of epoch %d.\" % epoch)\n",
    "                    \n",
    "            # sys.exit()\n",
    "            \n",
    "        # 所有的 epoch 都循环完之后（300个），存储验证集上最优模型的网络参数和 embeddings\n",
    "        print(\"Best epoch is %d, best hit@10 of validation set is %f\" % (best_epoch, best_hits10))\n",
    "        print(\"Storing checkpoint of best result at epoch %d ...\" % (best_epoch))\n",
    "        netparam_save_path = os.path.join(self.config.checkpoint_path, self.config.dataset + \"-netparam_best\" + \".ckpt\")\n",
    "        torch.save(best_model.state_dict(), netparam_save_path)\n",
    "\n",
    "        embed_save_path = os.path.join(self.config.checkpoint_path, self.config.dataset + \"-embed_best\" + \".json\")\n",
    "        with open(embed_save_path, 'w') as f:\n",
    "            f.write(json.dumps(self.get_parameters(best_model.state_dict(), 'list')))\n",
    "        print(\"Finished Storing best model and embeddings.\")\n",
    "\n",
    "        self.test(model = best_model)    # 测试结果会输出在 Linux 终端\n",
    "\n",
    "# 训练目标：FB15K237 Hits@10 至少要0.5，MR 二三百，MRR 0.2~0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing training model...\n",
      "Training model has been initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 | loss: 111.018544:   0%|          | 1/1000 [00:02<46:38,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Storing the model and embeddings of epoch 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 has finished, loss is 20.552946, validating ...:  10%|▉         | 99/1000 [02:06<18:34,  1.24s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "hits@10 of this validation epoch is: 0.09874839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 99 has finished, loss is 20.552946, validating ...:  10%|█         | 100/1000 [05:51<17:14:12, 68.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Storing the model and embeddings of epoch 99.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199 has finished, loss is 16.500203, validating ...:  20%|█▉        | 199/1000 [07:55<16:56,  1.27s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "hits@10 of this validation epoch is: 0.13724643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 199 has finished, loss is 16.500203, validating ...:  20%|██        | 200/1000 [11:41<15:18:06, 68.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Storing the model and embeddings of epoch 199.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299 has finished, loss is 14.423911, validating ...:  30%|██▉       | 299/1000 [13:45<14:23,  1.23s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "hits@10 of this validation epoch is: 0.15774709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 299 has finished, loss is 14.423911, validating ...:  30%|███       | 300/1000 [17:32<13:30:04, 69.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Storing the model and embeddings of epoch 299.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399 has finished, loss is 13.211458, validating ...:  40%|███▉      | 399/1000 [19:35<12:26,  1.24s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "hits@10 of this validation epoch is: 0.17522658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 399 has finished, loss is 13.211458, validating ...:  40%|████      | 400/1000 [23:20<11:26:11, 68.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Storing the model and embeddings of epoch 399.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499 has finished, loss is 12.430891, validating ...:  50%|████▉     | 499/1000 [25:26<10:20,  1.24s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "hits@10 of this validation epoch is: 0.19007337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 499 has finished, loss is 12.430891, validating ...:  50%|█████     | 500/1000 [29:11<9:32:35, 68.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Storing the model and embeddings of epoch 499.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599 has finished, loss is 11.718069, validating ...:  60%|█████▉    | 599/1000 [31:17<08:26,  1.26s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "hits@10 of this validation epoch is: 0.19624515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 599 has finished, loss is 11.718069, validating ...:  60%|██████    | 600/1000 [35:02<7:38:52, 68.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Storing the model and embeddings of epoch 599.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 699 has finished, loss is 11.053396, validating ...:  70%|██████▉   | 699/1000 [37:07<06:15,  1.25s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "hits@10 of this validation epoch is: 0.20418644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 699 has finished, loss is 11.053396, validating ...:  70%|███████   | 700/1000 [40:53<5:44:54, 68.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Storing the model and embeddings of epoch 699.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 799 has finished, loss is 10.800555, validating ...:  80%|███████▉  | 799/1000 [42:57<04:10,  1.25s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "hits@10 of this validation epoch is: 0.20910659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 799 has finished, loss is 10.800555, validating ...:  80%|████████  | 800/1000 [46:42<3:49:17, 68.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Storing the model and embeddings of epoch 799.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 899 has finished, loss is 10.343999, validating ...:  90%|████████▉ | 899/1000 [48:48<02:08,  1.27s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "hits@10 of this validation epoch is: 0.21122140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 899 has finished, loss is 10.343999, validating ...:  90%|█████████ | 900/1000 [52:33<1:54:44, 68.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Storing the model and embeddings of epoch 899.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999 has finished, loss is 10.143394, validating ...: 100%|█████████▉| 999/1000 [54:37<00:01,  1.24s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "hits@10 of this validation epoch is: 0.21493310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999 has finished, loss is 10.143394, validating ...: 100%|██████████| 1000/1000 [58:22<00:00,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Storing the model and embeddings of epoch 999.\n",
      "Best epoch is 999, best hit@10 of validation set is 0.214933\n",
      "Storing checkpoint of best result at epoch 999 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Storing best model and embeddings.\n",
      "Fetching model for test...\n",
      "Test model has been loaded.\n",
      "The total number of test triplets is 11586\n",
      "Testing...\n",
      "Finished testing.\n"
     ]
    }
   ],
   "source": [
    "runner = Runner(con, conv3d)\n",
    "if runner.config.mode == 'train':\n",
    "    runner.train_model()\n",
    "else:\n",
    "    runner.test(runner.model)\n",
    "    \n",
    "# 一测试就会崩掉的原因：需要 type_constrain（已解决）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
