{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import ctypes\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from numpy.random import RandomState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31343\n",
      "30\n",
      "92680\n",
      "11585\n",
      "11586\n",
      "926\n"
     ]
    }
   ],
   "source": [
    "use_gpu = True if torch.cuda.is_available() else False\n",
    "device = torch.device(\"cuda:1\" if use_gpu else \"cpu\")\n",
    "\n",
    "class Config():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.dim = 50\n",
    "        \n",
    "        # config of CNN\n",
    "        self.out_channels = 64      # 卷积核的个数\n",
    "        self.kernel_size = 2        # 卷积核大小的第一个维度，第二个维度是 3\n",
    "        self.drop_prob = 0.2        \n",
    "        \n",
    "        # config of training\n",
    "        self.learning_rate = 0.01      # ConvKB 中设为 0.01；改为0.015 Conv3D 就会停在 69 下不去，应该是陷入局部最优了\n",
    "        self.batch_num = 100\n",
    "        self.epoch_num = 1000\n",
    "        self.lmbda = 0.2              # ConvKB 中是 0.2\n",
    "        self.opt_method = \"Adagrad\"\n",
    "        \n",
    "        # config of model storage\n",
    "        self.vali_epoch = 100\n",
    "        self.save_epoch = 100 \n",
    "        self.mode = \"train\"        # \"train\" or \"test\"\n",
    "        self.checkpoint_path = \"./checkpoints_Conv1d\"\n",
    "        \n",
    "        # 调用 C++ 封装的库文件 Base.io\n",
    "        self.clib = ctypes.cdll.LoadLibrary(\"./Base.so\")\n",
    "        self.dataset = \"IMDB_sub\"    # \"WN18\" or \"WN18RR\" or \"FB15K\" or \"FB15K237\"\n",
    "        self.in_path = \"./\" + self.dataset + \"/\"    # 将数据集路径传递给 Base.io\n",
    "        \n",
    "        # negative sampling\n",
    "        self.clib.sampling.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_int64,\n",
    "            ctypes.c_int64,\n",
    "            ctypes.c_int64,\n",
    "        ]\n",
    "        \n",
    "        # validation dataset\n",
    "        self.clib.getValidHeadBatch.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "        ]\n",
    "        self.clib.getValidTailBatch.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "        ]\n",
    "        self.clib.validHead.argtypes = [ctypes.c_void_p]\n",
    "        self.clib.validTail.argtypes = [ctypes.c_void_p]\n",
    "        \n",
    "        # link prediction test dataset\n",
    "        self.clib.getHeadBatch.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "        ]\n",
    "        self.clib.getTailBatch.argtypes = [\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "            ctypes.c_void_p,\n",
    "        ]\n",
    "        self.clib.testHead.argtypes = [ctypes.c_void_p]\n",
    "        self.clib.testTail.argtypes = [ctypes.c_void_p]\n",
    "        \n",
    "        self.test_file = \"\"\n",
    "        self.clib.setInPath(ctypes.create_string_buffer(self.in_path.encode(), len(self.in_path)*2))\n",
    "        self.clib.setTestFilePath(ctypes.create_string_buffer(self.test_file.encode(), len(self.test_file)*2))\n",
    "        \n",
    "        self.clib.setBern(0)\n",
    "        self.clib.setWorkThreads(8)\n",
    "        self.clib.randReset()\n",
    "        \n",
    "        self.clib.importTrainFiles()\n",
    "        self.clib.importTestFiles()\n",
    "        \n",
    "        # 数据集统计信息\n",
    "        self.ent_num = self.clib.getEntityTotal()\n",
    "        self.rel_num = self.clib.getRelationTotal()\n",
    "        self.train_num = self.clib.getTrainTotal()\n",
    "        self.vali_num = self.clib.getValidTotal()\n",
    "        self.test_num = self.clib.getTestTotal()\n",
    "        \n",
    "        self.batch_size = int(self.train_num / self.batch_num)\n",
    "        \n",
    "con = Config()\n",
    "print(con.ent_num)\n",
    "print(con.rel_num)\n",
    "print(con.train_num)\n",
    "print(con.vali_num)\n",
    "print(con.test_num)\n",
    "print(con.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(31343, 50)\n",
      "Embedding(30, 50)\n"
     ]
    }
   ],
   "source": [
    "# 为 CPU 设置用于生成随机数的种子，以使得结果是确定的\n",
    "torch.manual_seed(123)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(123)    # 使用多个 GPU 的话，为所有的 GPU 设置种子，torch.cuda.manual_seed() 是为当前 GPU 设置种子\n",
    "\n",
    "    \n",
    "class Conv1D(nn.Module):\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(Conv1D, self).__init__()\n",
    "        \n",
    "        self.config = config\n",
    "        self.batch_h = None\n",
    "        self.batch_t = None\n",
    "        self.batch_r = None\n",
    "        self.batch_y = None\n",
    "        \n",
    "        self.ent_embeddings = nn.Embedding(self.config.ent_num, self.config.dim)\n",
    "        self.rel_embeddings = nn.Embedding(self.config.rel_num, self.config.dim)\n",
    "        \n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=1)\n",
    "        self.conv_layer = nn.Conv2d(in_channels=1, out_channels=self.config.out_channels, kernel_size=(self.config.kernel_size, 3))\n",
    "        self.bn2 = nn.BatchNorm2d(num_features = self.config.out_channels)    # 卷积之后进行 batch normalization\n",
    "        self.dropout = nn.Dropout(self.config.drop_prob)\n",
    "        self.nonlinear = nn.ReLU()    # 也可以尝试 nn.Tanh 等其他激活函数\n",
    "        self.fc_layer = nn.Linear(in_features=(self.config.dim-self.config.kernel_size+1)*self.config.out_channels, \n",
    "                                  out_features=1, bias=False)\n",
    "        self.criterion = nn.Softplus()    # softplus 的公式就是：y = log(1+exp(x))\n",
    "        \n",
    "        \n",
    "        # 初始化 embeddings\n",
    "        nn.init.xavier_uniform_(self.ent_embeddings.weight.data)\n",
    "        nn.init.xavier_uniform_(self.rel_embeddings.weight.data)\n",
    "        \n",
    "        # 初始化卷积层和全连接层的参数\n",
    "        nn.init.xavier_uniform_(self.conv_layer.weight.data)\n",
    "        nn.init.xavier_uniform_(self.fc_layer.weight.data)\n",
    "        \n",
    "    \n",
    "    def cal_score(self):\n",
    "        \n",
    "        # 查表得到 embeddings\n",
    "        h = self.ent_embeddings(self.batch_h)\n",
    "        t = self.ent_embeddings(self.batch_t)\n",
    "        r = self.rel_embeddings(self.batch_r)\n",
    "        \n",
    "        h = h.unsqueeze(1)    # unsqueeze 函数的作用是在第二维增加一个维度 1，h 的形状由 batch size * dim 变为 batch size * 1 * dim\n",
    "        t = t.unsqueeze(1)\n",
    "        r = r.unsqueeze(1)\n",
    "        \n",
    "        conv_input = torch.cat([h, r, t], 1)       # 在第二个维度进行拼接，形状为 batch size * 3 * dim\n",
    "        \n",
    "        # 使用 nn.Conv1d实现方式时，将下面两句 transpose 和 unsqueeze 的操作注释掉\n",
    "        conv_input = conv_input.transpose(1, 2)    # 将第二个维度和第三个维度进行交换，形状变为 batch size * dim * 3\n",
    "        conv_input = conv_input.unsqueeze(1)       # 卷积层的输入需要是 4D， batch size * 1 * dim * 3\n",
    "        # 这里总结一下 1D 和 2D 卷积的共性：输入都是 4D，第一个维度是 batch size，第二个维度是通道数（即有几个矩阵），第三和第四维度指示矩阵的形状\n",
    "        \n",
    "        conv_input = self.bn1(conv_input)          # 卷积前的 batch normalization\n",
    "        conv_output = self.conv_layer(conv_input)  # 卷积，输出形状为 batch size * out_channels(卷积核数量) * (dim-self.config.kernel_size+1) * 1\n",
    "        conv_output = self.bn2(conv_output)        # 卷积后的 batch normalization，形状不变\n",
    "        conv_output = self.nonlinear(conv_output)  # 过激活函数，形状不变\n",
    "        # 忽略 batch size，就是拍扁（拼接）为一条线\n",
    "        conv_output = conv_output.view(-1, self.config.out_channels * (self.config.dim-self.config.kernel_size+1))\n",
    "        # 卷积输出形状为二维平面，第一个维度是 batch size，第二维度是 feature map 的长条\n",
    "        # batch size * (self.config.out_channels * (self.config.hidden_size-self.config.kernel_size+1))\n",
    "        \n",
    "        fc_input = self.dropout(conv_output)\n",
    "        fc_output = self.fc_layer(fc_input)    # batch size * 1\n",
    "        score = fc_output.view(-1)             # batch size\n",
    "        # print(score)\n",
    "        return -score\n",
    "    \n",
    "    \n",
    "    def forward(self):\n",
    "        '''\n",
    "        前向传播计算 loss，返回该 batch 的 loss\n",
    "        '''\n",
    "        batch_score = self.cal_score()\n",
    "        \n",
    "        h = self.ent_embeddings(self.batch_h)\n",
    "        r = self.rel_embeddings(self.batch_r)\n",
    "        t = self.ent_embeddings(self.batch_t)\n",
    "        # 跪了orz，我说为什么正确率上不去，逐行对代码才发现又抄错了，r 的查表也写成了 ent_embeddings\n",
    "        # 改过来之后 loss 就下降得很快了\n",
    "        \n",
    "        l2_regular = torch.mean(h ** 2) + torch.mean(t ** 2) + torch.mean(r ** 2)\n",
    "        for p in self.conv_layer.parameters():\n",
    "            l2_regular += p.norm(2)\n",
    "        for p in self.fc_layer.parameters():\n",
    "            l2_regular += p.norm(2)\n",
    "            \n",
    "        # 该 batch 的 loss：该 batch 中所有样本得分的平均值 + 正则项\n",
    "        mean = torch.mean(self.criterion(self.batch_y * batch_score))    # 三维卷积的话，这部分降到 0.69 就死活下不去了\n",
    "        regular = self.config.lmbda * l2_regular\n",
    "        # print(mean.data, regular)\n",
    "        loss = mean + regular\n",
    "        # print(loss.data)\n",
    "        return loss\n",
    "\n",
    "conv1d = Conv1D(con)\n",
    "conv1d.batch_h = torch.LongTensor([1,40,5,4,6,79])\n",
    "conv1d.batch_r = torch.LongTensor([5,4,2,4,1,9])\n",
    "conv1d.batch_t = torch.LongTensor([3,60,80,3,56,7])\n",
    "conv1d.batch_y = torch.LongTensor([1,1,1,-1,-1,-1])\n",
    "conv1d()\n",
    "print(conv1d.ent_embeddings)\n",
    "print(conv1d.rel_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runner():\n",
    "    \n",
    "    def __init__(self, config, model):\n",
    "        self.config = config\n",
    "        self.model = model\n",
    "        self.clib = self.config.clib\n",
    "        \n",
    "    def set_model(self, mode = 'train'):\n",
    "        self.model.to(device)\n",
    "        \n",
    "        if mode == 'train':    # 训练模型\n",
    "            print(\"Initializing training model...\")\n",
    "            # 为训练模型设定优化器\n",
    "            if self.config.opt_method == \"Adagrad\":\n",
    "                self.optimizer = optim.Adagrad(\n",
    "                    params = self.model.parameters(),\n",
    "                    lr = self.config.learning_rate,\n",
    "                    lr_decay = 0,\n",
    "                    weight_decay = 0\n",
    "                )\n",
    "            elif self.config.opt_method == \"Adadelta\":\n",
    "                self.optimizer = optim.Adadelta(\n",
    "                    params = self.model.parameters(),\n",
    "                    lr = self.config.learning_rate,\n",
    "                    weight_decay = 0\n",
    "                )\n",
    "            elif self.config.opt_method == \"Adam\":\n",
    "                self.optimizer = optim.Adam(\n",
    "                    params = self.model.parameters(),\n",
    "                    lr = self.config.learning_rate,\n",
    "                    weight_decay = 0\n",
    "                )\n",
    "            else:    # 不是以上三种的话就用 SGD\n",
    "                self.optimizer = optim.SGD(\n",
    "                    params = self.model.parameters(),\n",
    "                    lr = self.config.learning_rate,\n",
    "                    weight_decay = 0\n",
    "                )\n",
    "            print(\"Training model has been initialized.\")\n",
    "        else:                           # mode == 'test'，从 checkpoints 中载入模型，用于测试\n",
    "            print(\"Fetching model for test...\")\n",
    "            ckpt_path = os.path.join(\"./checkpoints_Conv1d/\", self.config.dataset + \"-netparam_best\" + \".ckpt\")  \n",
    "            self.model.load_state_dict(torch.load(ckpt_path))\n",
    "            self.model.to(device)\n",
    "            self.model.eval()\n",
    "            print(\"Test model has been loaded.\")\n",
    "    \n",
    "    def get_parameters(self, param_dict, mode = 'numpy'):\n",
    "        '''\n",
    "        从 model 中剥离出参数\n",
    "        '''\n",
    "        res = dict()\n",
    "        for param in param_dict:\n",
    "            if mode == 'numpy':\n",
    "                res[param] = param_dict[param].cpu().numpy()\n",
    "            elif mode == 'list':\n",
    "                res[param] = param_dict[param].cpu().numpy().tolist()\n",
    "            else:\n",
    "                res[param] = param_dict[param]\n",
    "        return res\n",
    "    \n",
    "    def neg_sample(self):\n",
    "        '''\n",
    "        对 batch 数据进行负采样\n",
    "        无返回值\n",
    "        '''\n",
    "        self.negative_ent = 1    # 负样本实体一个\n",
    "        self.negative_rel = 0\n",
    "        self.batch_seq_size = self.config.batch_size * (1 + self.negative_ent + self.negative_rel)\n",
    "        \n",
    "        self.batch_h = np.zeros(self.batch_seq_size, dtype = np.int64)    # 容量是 batch size 的两倍，用于盛放负样本\n",
    "        self.batch_t = np.zeros(self.batch_seq_size, dtype = np.int64)\n",
    "        self.batch_r = np.zeros(self.batch_seq_size, dtype = np.int64)\n",
    "        self.batch_y = np.zeros(self.batch_seq_size, dtype = np.float32)\n",
    "\n",
    "        self.batch_h_addr = self.batch_h.__array_interface__[\"data\"][0]\n",
    "        self.batch_t_addr = self.batch_t.__array_interface__[\"data\"][0]\n",
    "        self.batch_r_addr = self.batch_r.__array_interface__[\"data\"][0]\n",
    "        self.batch_y_addr = self.batch_y.__array_interface__[\"data\"][0]\n",
    "        \n",
    "        # 这一步将数据集中实体和关系的 id 传进来\n",
    "        # print(self.batch_y)\n",
    "        self.clib.sampling(\n",
    "            self.batch_h_addr,    # 头实体 batch 的地址，传给 clib 函数的指针\n",
    "            self.batch_t_addr,\n",
    "            self.batch_r_addr,\n",
    "            self.batch_y_addr,\n",
    "            self.config.batch_size,\n",
    "            self.negative_ent,\n",
    "            self.negative_rel\n",
    "        )\n",
    "    \n",
    "    def train_batch(self):\n",
    "        '''\n",
    "        使用 self.model 训练一个 batch 的数据\n",
    "        return: 该 batch 的 loss\n",
    "        '''\n",
    "        self.model.train()\n",
    "        # 向模型喂一个 batch 的数据\n",
    "        self.model.batch_h = torch.from_numpy(self.batch_h).to(device)    # numpy 数组转为 Tensor\n",
    "        self.model.batch_t = torch.from_numpy(self.batch_t).to(device)\n",
    "        self.model.batch_r = torch.from_numpy(self.batch_r).to(device)\n",
    "        self.model.batch_y = torch.from_numpy(self.batch_y).to(device)\n",
    "        # print(self.model.batch_y)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        loss = self.model()    # 会自动调用 forward() 函数\n",
    "        loss.backward()        # 误差反向传播\n",
    "        # 由于在反向传播的过程中会发生梯度消失/爆炸，因此设定阈值，当梯度大于/小于阈值时候，将梯度缩放为阈值\n",
    "        nn.utils.clip_grad_norm_(parameters = self.model.parameters(), max_norm = 0.5, norm_type = 2)\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "    \n",
    "    def test_batch(self, model, batch_h, batch_t, batch_r):\n",
    "        '''\n",
    "        测试一个 batch 的数据\n",
    "        batch_h: numpy array\n",
    "        batch_t: numpy array\n",
    "        batch_r: numpy array\n",
    "        return: 该 test batch 的三元组得分\n",
    "        '''\n",
    "        # model.train()  将模块设置为训练模式，使用BatchNormalizetion()和Dropout()\n",
    "        # model.eval()   将模块设置为评估模式，不使用BatchNormalization()和Dropout()\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            model.batch_h = torch.from_numpy(batch_h).to(device)\n",
    "            model.batch_t = torch.from_numpy(batch_t).to(device)\n",
    "            model.batch_r = torch.from_numpy(batch_r).to(device)\n",
    "        # print(\"test batch res is:\")\n",
    "        res = model.cal_score().cpu().data.numpy()\n",
    "        # print(res.shape)\n",
    "        return res\n",
    "        \n",
    "    def validation(self, model):\n",
    "        '''\n",
    "        验证模型\n",
    "        '''\n",
    "        model.eval()\n",
    "        self.vali_h = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.vali_t = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.vali_r = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.vali_h_addr = self.vali_h.__array_interface__[\"data\"][0]    # array 的内存地址\n",
    "        self.vali_t_addr = self.vali_t.__array_interface__[\"data\"][0]\n",
    "        self.vali_r_addr = self.vali_r.__array_interface__[\"data\"][0]\n",
    "        \n",
    "        self.clib.validInit()\n",
    "        self.clib.getValidHit10.restype = ctypes.c_float\n",
    "        \n",
    "        print(\"The total number of validation triplets is %d\" % self.config.vali_num)\n",
    "        for i in range(self.config.vali_num):\n",
    "            sys.stdout.write(\"%d \\r\" % i)    # 动态打印输出\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            # 之前运行这一步服务就会\n",
    "            # 原因：self.vali_r = np.zeros(self.config.ent_num, dtype=np.int64)，写成了rel_num，以为是原代码错了，但其实没有，自作聪明的结果\n",
    "            self.clib.getValidHeadBatch(self.vali_h_addr, self.vali_t_addr, self.vali_r_addr)\n",
    "            res = self.test_batch(model, self.vali_h, self.vali_t, self.vali_r)\n",
    "            self.clib.validHead(res.__array_interface__[\"data\"][0])\n",
    "            \n",
    "            self.clib.getValidTailBatch(self.vali_h_addr, self.vali_t_addr, self.vali_r_addr)\n",
    "            res = self.test_batch(model, self.vali_h, self.vali_t, self.vali_r)\n",
    "            self.clib.validTail(res.__array_interface__[\"data\"][0])\n",
    "            \n",
    "            # 第一个 batch 的 Hits@10 res 是 0.0\n",
    "        return self.clib.getValidHit10()   # 训练时的验证步骤，需要返回 hits@10 结果\n",
    "    \n",
    "    def test(self, model):\n",
    "        self.set_model(mode = 'test')\n",
    "        # 只做链接预测实验\n",
    "        \n",
    "        print(\"The total number of test triplets is %d\" % self.config.test_num)\n",
    "\n",
    "        self.test_h = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.test_t = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.test_r = np.zeros(self.config.ent_num, dtype=np.int64)\n",
    "        self.test_h_addr = self.test_h.__array_interface__[\"data\"][0]\n",
    "        self.test_t_addr = self.test_t.__array_interface__[\"data\"][0]\n",
    "        self.test_r_addr = self.test_r.__array_interface__[\"data\"][0]\n",
    "        \n",
    "        print(\"Testing...\")\n",
    "        for i in range(self.config.test_num):\n",
    "            sys.stdout.write(\"%d \\r\" % i)    # 动态打印输出\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            self.clib.getHeadBatch(self.test_h_addr, self.test_t_addr, self.test_r_addr)\n",
    "            res = self.test_batch(model, self.test_h, self.test_t, self.test_r)\n",
    "            self.clib.testHead(res.__array_interface__[\"data\"][0])\n",
    "\n",
    "            self.clib.getTailBatch(self.test_h_addr, self.test_t_addr, self.test_r_addr)\n",
    "            res = self.test_batch(model, self.test_h, self.test_t, self.test_r)\n",
    "            self.clib.testTail(res.__array_interface__[\"data\"][0])\n",
    "\n",
    "        self.clib.test_link_prediction()\n",
    "        print(\"Finished testing.\")\n",
    "    \n",
    "    def train_model(self):\n",
    "        if not os.path.exists(self.config.checkpoint_path):\n",
    "            os.mkdir(self.config.checkpoint_path)\n",
    "            \n",
    "        self.set_model(mode = self.config.mode)\n",
    "        \n",
    "        best_epoch = 0\n",
    "        best_hits10 = 0.0\n",
    "        best_model = self.model\n",
    "\n",
    "        epochs = tqdm(range(self.config.epoch_num))\n",
    "        \n",
    "        for epoch in epochs:\n",
    "            res = 0.0    # 用于累加本 epoch 各个 batch 的 loss\n",
    "            for batch in range(self.config.batch_num):    # 训练一个batch\n",
    "                self.neg_sample()    # 负采样\n",
    "                loss = self.train_batch()    # 训练一个 batch 为一个 step\n",
    "                # print(\"batch loss: %f\" % loss)\n",
    "                res += loss\n",
    "                \n",
    "            epochs.set_description(\"Epoch %d | loss: %f\" % (epoch, res))    # 输出进度条的描述\n",
    "            # 问题：loss到了69左右就不下降了，但是 50 epoch 后验证集正确率还是达到了 50多（但不再增长），所以应该问题不大\n",
    "            # 应该是网络比较复杂，在数据集上很快就拟合好了\n",
    "            # 验证集准确率上升很快，测试集上却没有跑出结果，应该是过拟合了\n",
    "            # 下一步是学习 ConvE 疯狂 dropout\n",
    "            \n",
    "            if (epoch + 1) % self.config.save_epoch == 0:\n",
    "                epochs.set_description(\"Epoch %d has finished, loss is %f, saving checkpoint ...\" % (epoch, res))\n",
    "                # 存储 checkpoint\n",
    "                save_path = os.path.join(self.config.checkpoint_path, self.config.dataset + \"-\" + str(epoch) + \".ckpt\")\n",
    "                torch.save(self.model.state_dict(), save_path)\n",
    "            \n",
    "            if (epoch + 1) % self.config.vali_epoch == 0:\n",
    "                epochs.set_description(\"Epoch %d has finished, loss is %f, validating ...\" % (epoch, res))\n",
    "                hits10 = self.validation(self.model)\n",
    "                print(\"hits@10 of this validation epoch is: %.8f\" % hits10)\n",
    "#                 print(\"Testing on test set ...\")\n",
    "#                 self.test(self.model)\n",
    "#                 print(\"Test result is printed on Linux shell.\")\n",
    "                \n",
    "                if hits10 > best_hits10:\n",
    "                    best_hits10 = hits10\n",
    "                    best_epoch = epoch\n",
    "                    best_model = self.model\n",
    "                    \n",
    "            # sys.exit()\n",
    "            \n",
    "        # 所有的 epoch 都循环完之后（300个），存储验证集上最优模型的网络参数和 embeddings\n",
    "        print(\"Best epoch is %d, best hit@10 of validation set is %f\" % (best_epoch, best_hits10))\n",
    "        print(\"Storing checkpoint of best result at epoch %d ...\" % (best_epoch))\n",
    "        netparam_save_path = os.path.join(self.config.checkpoint_path, self.config.dataset + \"-netparam_best\" + \".ckpt\")\n",
    "        torch.save(best_model.state_dict(), netparam_save_path)\n",
    "\n",
    "        embed_save_path = os.path.join(self.config.checkpoint_path, self.config.dataset + \"-embed_best\" + \".json\")\n",
    "        with open(embed_save_path, 'w') as f:\n",
    "            f.write(json.dumps(self.get_parameters(best_model.state_dict(), 'list')))\n",
    "        print(\"Finished Storing best model and embeddings.\")\n",
    "\n",
    "        self.test(model = best_model)    # 测试结果会输出在 Linux 终端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing training model...\n",
      "Training model has been initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99 has finished, loss is 17.745296, validating ...:  10%|▉         | 99/1000 [01:42<15:40,  1.04s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "11584 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 99 has finished, loss is 17.745296, validating ...:  10%|█         | 100/1000 [07:18<25:25:33, 101.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@10 of this validation epoch is: 0.08662063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 199 has finished, loss is 14.584256, validating ...:  20%|█▉        | 199/1000 [09:01<13:53,  1.04s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "11584 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 199 has finished, loss is 14.584256, validating ...:  20%|██        | 200/1000 [14:36<22:36:18, 101.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@10 of this validation epoch is: 0.10677600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 299 has finished, loss is 12.996477, validating ...:  30%|██▉       | 299/1000 [16:20<12:05,  1.04s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "11584 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 299 has finished, loss is 12.996477, validating ...:  30%|███       | 300/1000 [21:55<19:46:16, 101.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@10 of this validation epoch is: 0.11575313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 399 has finished, loss is 12.081664, validating ...:  40%|███▉      | 399/1000 [23:37<10:36,  1.06s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "11584 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 399 has finished, loss is 12.081664, validating ...:  40%|████      | 400/1000 [29:14<17:01:15, 102.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@10 of this validation epoch is: 0.12296073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 499 has finished, loss is 11.409656, validating ...:  50%|████▉     | 499/1000 [30:53<08:15,  1.01it/s]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "11584 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 499 has finished, loss is 11.409656, validating ...:  50%|█████     | 500/1000 [36:30<14:10:46, 102.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@10 of this validation epoch is: 0.12779456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 599 has finished, loss is 10.950257, validating ...:  60%|█████▉    | 599/1000 [38:13<06:52,  1.03s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "11584 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 599 has finished, loss is 10.950257, validating ...:  60%|██████    | 600/1000 [43:50<11:20:43, 102.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@10 of this validation epoch is: 0.13025464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 699 has finished, loss is 10.492991, validating ...:  70%|██████▉   | 699/1000 [45:33<04:54,  1.02it/s]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "11584 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 699 has finished, loss is 10.492991, validating ...:  70%|███████   | 700/1000 [51:10<8:30:13, 102.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@10 of this validation epoch is: 0.13318947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 799 has finished, loss is 10.119544, validating ...:  80%|███████▉  | 799/1000 [52:49<03:26,  1.03s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "11584 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 799 has finished, loss is 10.119544, validating ...:  80%|████████  | 800/1000 [58:26<5:40:10, 102.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@10 of this validation epoch is: 0.13513163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 899 has finished, loss is 9.842671, validating ...:  90%|████████▉ | 899/1000 [1:00:08<01:44,  1.04s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "11584 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 899 has finished, loss is 9.842671, validating ...:  90%|█████████ | 900/1000 [1:05:44<2:49:48, 101.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@10 of this validation epoch is: 0.13564955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999 has finished, loss is 9.618088, validating ...: 100%|█████████▉| 999/1000 [1:07:27<00:01,  1.03s/it]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of validation triplets is 11585\n",
      "11584 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 999 has finished, loss is 9.618088, validating ...: 100%|██████████| 1000/1000 [1:13:03<00:00,  4.38s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hits@10 of this validation epoch is: 0.13832542\n",
      "Best epoch is 999, best hit@10 of validation set is 0.138325\n",
      "Storing checkpoint of best result at epoch 999 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Storing best model and embeddings.\n",
      "Fetching model for test...\n",
      "Test model has been loaded.\n",
      "The total number of test triplets is 11586\n",
      "Testing...\n",
      "Finished testing.\n"
     ]
    }
   ],
   "source": [
    "runner = Runner(con, conv1d)\n",
    "if runner.config.mode == 'train':\n",
    "    runner.train_model()\n",
    "else:\n",
    "    runner.test(runner.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
